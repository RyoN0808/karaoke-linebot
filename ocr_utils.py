import os
import re
import io
import cv2
import logging
from typing import Optional
from PIL import Image
import numpy as np
from google.cloud import vision
from google.oauth2 import service_account
from google.cloud.vision_v1.types.image_annotator import AnnotateImageResponse

# ==============================
# ã‚¹ã‚³ã‚¢æŠ½å‡ºå‡¦ç†
# ==============================

def _calc_area(bounding_poly) -> float:
    """
    ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒãƒªã‚´ãƒ³ã®é ‚ç‚¹æƒ…å ±ã‹ã‚‰ã€ã‚ˆã‚Šå …ç‰¢ãªæ–¹æ³•ã§é¢ç©ã‚’ç®—å‡ºã™ã‚‹ã€‚
    â€»é ‚ç‚¹ãŒ3ç‚¹ä»¥ä¸Šã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€å„é ‚ç‚¹ã®æœ€å°ï¼æœ€å¤§ã®x,yå€¤ã‹ã‚‰å¹…ã¨é«˜ã•ã‚’ç®—å‡ºã€‚
    """
    if not bounding_poly or not bounding_poly.vertices:
        return 0.0
    vertices = bounding_poly.vertices
    if len(vertices) < 3:
        return 0.0
    xs = [v.x for v in vertices]
    ys = [v.y for v in vertices]
    width = max(xs) - min(xs)
    height = max(ys) - min(ys)
    return width * height

def _extract_score(ocr_response: AnnotateImageResponse) -> Optional[float]:
    texts = ocr_response.text_annotations
    if not texts:
        return None

    candidates = []
    # texts[0] ã¯å…¨ä½“ã®ãƒ†ã‚­ã‚¹ãƒˆãªã®ã§ã€ãã‚Œä»¥é™ã‚’å€‹åˆ¥ã®å€™è£œã¨ã™ã‚‹
    for annotation in texts[1:]:
        text = annotation.description
        if "ç‚¹" not in text:
            continue
        # æ•°å­—ã®éƒ¨åˆ†ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆä¾‹ï¼š9.500 ã‚„ 10.000 ãªã©ï¼‰
        if not re.search(r"\d+[.,]?\d*", text):
            continue

        area = _calc_area(annotation.bounding_poly)
        # ã‚«ãƒ³ãƒã‚’ãƒ‰ãƒƒãƒˆã«ç½®æ›ã—ã¦ã‹ã‚‰æ•°å€¤éƒ¨åˆ†ã‚’æŠ½å‡º
        score_match = re.search(r"\d+[.,]?\d*", text.replace(",", "."))
        if score_match:
            try:
                score = float(score_match.group().replace(",", "."))
                candidates.append((score, area, text))
            except ValueError:
                continue

    if not candidates:
        logging.warning("â— ã‚¹ã‚³ã‚¢å€™è£œãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return None

    # é¢ç©ãŒå¤§ãã„é †ã«ã‚½ãƒ¼ãƒˆï¼ˆã‚ˆã‚Šå¤§ãã„é ˜åŸŸï¼ä¿¡é ¼åº¦ãŒé«˜ã„ã¨ä»®å®šï¼‰
    candidates.sort(key=lambda x: x[1], reverse=True)
    logging.debug(f"âœ… ã‚¹ã‚³ã‚¢å€™è£œä¸€è¦§: {candidates}")
    return candidates[0][0]

# ==============================
# é …ç›®ã”ã¨ã®OCRåˆ‡ã‚Šå‡ºã—
# ==============================
SCORE_REGION = (100, 400, 500, 500)
SONG_NAME_REGION = (600, 400, 1000, 450)
ARTIST_NAME_REGION = (600, 450, 1000, 500)

def crop_region(image_path, region):
    img = cv2.imread(image_path)
    if img is None:
        logging.error(f"ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
        return None
    x1, y1, x2, y2 = region
    cropped = img[y1:y2, x1:x2]
    base, ext = os.path.splitext(image_path)
    temp_path = f"{base}_crop_{x1}_{y1}{ext}"
    cv2.imwrite(temp_path, cropped)
    return temp_path

def crop_regions_for_fields(image_path):
    score_crop = crop_region(image_path, SCORE_REGION)
    song_crop = crop_region(image_path, SONG_NAME_REGION)
    artist_crop = crop_region(image_path, ARTIST_NAME_REGION)
    return score_crop, song_crop, artist_crop

def ocr_image(image_path, client):
    with io.open(image_path, 'rb') as image_file:
        content = image_file.read()

    image = vision.Image(content=content)
    response = client.text_detection(image=image)
    texts = response.text_annotations
    return texts[0].description if texts else ""

def extract_text_from_image(image_path):
    credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
    if not credentials_path:
        logging.error("GOOGLE_APPLICATION_CREDENTIALS ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return ""
    credentials = service_account.Credentials.from_service_account_file(credentials_path)
    client = vision.ImageAnnotatorClient(credentials=credentials)
    return ocr_image(image_path, client)

# ==============================
# ä¿®æ­£ã‚³ãƒãƒ³ãƒ‰é–¢é€£
# ==============================

def is_correction_command(text: str) -> bool:
    return text == "ä¿®æ­£" or text.lower() == "fix"

def get_correction_menu() -> str:
    return "ğŸ”§ ä¿®æ­£ã—ãŸã„é …ç›®ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š\n[ã‚¹ã‚³ã‚¢] [æ›²å] [ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ] [ã‚³ãƒ¡ãƒ³ãƒˆ]"

def is_correction_field_selection(text: str) -> bool:
    return text in ["ã‚¹ã‚³ã‚¢", "æ›²å", "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ", "ã‚³ãƒ¡ãƒ³ãƒˆ"]

def set_user_correction_step(user_id, field):
    from supabase_client import supabase
    supabase.table("corrections").upsert({
        "user_id": user_id,
        "field": field,
        "timestamp": "now()"
    }).execute()

def get_user_correction_step(user_id):
    from supabase_client import supabase
    resp = supabase.table("corrections").select("field").eq("user_id", user_id).single().execute()
    return resp.data.get("field") if resp.data else None

def clear_user_correction_step(user_id):
    from supabase_client import supabase
    supabase.table("corrections").delete().eq("user_id", user_id).execute()

def parse_correction_command(text: str):
    result = {}
    # scoreã®æ­£è¦è¡¨ç¾ã‚’ã‚ˆã‚ŠæŸ”è»Ÿã«å¤‰æ›´ï¼ˆä¾‹ï¼š1æ¡ä»¥ä¸Šã€å°‘æ•°éƒ¨ã‚‚æŸ”è»Ÿã«ãƒãƒƒãƒï¼‰
    patterns = {
        "score": r"score[:ï¼š]\s*(\d+[.,]?\d+)",
        "song_name": r"(?:æ›²å|song)[:ï¼š]\s*(\S+)",
        "artist_name": r"(?:ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ|artist)[:ï¼š]\s*(\S+)",
        "comment": r"(?:ã‚³ãƒ¡ãƒ³ãƒˆ|comment)[:ï¼š]\s*(.+)"
    }
    for key, pattern in patterns.items():
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            result[key] = match.group(1).strip()
    return result
